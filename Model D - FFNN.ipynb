{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed,LSTM,Conv1D,Dense,Flatten,ConvLSTM2D,MaxPooling1D, Dropout\n",
    "# from tensorflow.tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import KFold \n",
    "from IPython.display import clear_output\n",
    "from scipy.interpolate import interp1d\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from scipy import stats \n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(x):\n",
    "    if x==\" \":\n",
    "        return np.nan\n",
    "    else :\n",
    "        return float(x)\n",
    "\n",
    "def norm(x, train_mean, train_std):\n",
    "    return (x - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "features = [\"temp\",\"precip\",\"rel_humidity\",\"wind_dir\",\"wind_spd\",\"atmos_press\"]\n",
    "for feature in features : \n",
    "    train[feature] = train[feature].apply(lambda x: [ replace_nan(X) for X in x.replace(\"nan\",\" \").split(\",\")])\n",
    "    test[feature] = test[feature].apply(lambda x: [ replace_nan(X)  for X in x.replace(\"nan\",\" \").split(\",\")])\n",
    "\n",
    "patterns =  len(train['temp'])\n",
    "entries =  len(train['temp'][0])\n",
    "num_features = len(features)\n",
    "labels = np.array(train['target'])\n",
    "count = 0\n",
    "inputs = [0, 0, 0, 0, 0, 0]\n",
    "for F in features:\n",
    "    with open(F + '.txt', 'r') as f:\n",
    "        l = ([[float(num) for num in line.split(' ')] for line in f])\n",
    "    l = np.array(l)\n",
    "    inputs[count] = l\n",
    "    count += 1\n",
    "    \n",
    "temperature, precipitation, humidity, wind_d, wind_s, pressure = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], inputs[5]\n",
    "\n",
    "# Locations to numbers\n",
    "for i in range(patterns):\n",
    "    if train['location'][i] == 'A':\n",
    "        train['location'][i] = -1\n",
    "    elif train['location'][i] == 'B':\n",
    "        train['location'][i] = -0.5\n",
    "    elif train['location'][i] == 'C':\n",
    "        train['location'][i] = 0.05\n",
    "    elif train['location'][i] == 'D':\n",
    "        train['location'][i] = 0.5\n",
    "    elif train['location'][i] == 'E':\n",
    "        train['location'][i] = 1\n",
    "\n",
    "vector = np.zeros((patterns, entries*(num_features + 1)))\n",
    "for i in range(patterns): \n",
    "    vector[i,0:121],vector[i,121:242], vector[i,242:363], vector[i,363:484], vector[i,484:605], vector[i,605:726], vector[i,726:] = temperature[i], precipitation[i], humidity[i], wind_d[i], wind_s[i], pressure[i], np.ones(121)*train['location'][i]\n",
    "clear_output()\n",
    "\n",
    "vector_train, vector_test, labels_train, labels_test = train_test_split(vector, labels, test_size = 0.3, random_state = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFNN(X, y, epochs, folds, batchsize, sim):\n",
    "    \"----------------------------------------------------------------------\"\n",
    "    \"This function returns a trained and tested model\"\n",
    "    \"model based on data x and labels y over epochs.\"\n",
    "\n",
    "    \"The input data X must be of a matrix or tensor size only\"\n",
    "    \"With shape = [patterns, features, entries, depth], depth can be null\"\n",
    "    \"and is assumed 1\"\n",
    "    \"----------------------------------------------------------------------\"\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        kf = KFold(n_splits = folds, shuffle = True, random_state = 777)\n",
    "    #     stop = EarlyStopping(monitor='val_loss', patience = 20, mode='min', verbose=0)\n",
    "        training_loss_fold = np.zeros((folds, epochs))\n",
    "        testing_loss_fold = np.zeros((folds, epochs))\n",
    "\n",
    "        fold = -1\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            clear_output()\n",
    "            fold += 1\n",
    "            print(\"Simulation {}\\nFold {}\".format(sim,fold))\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            # This standardizes the data.\n",
    "            start = 0\n",
    "            for i in range(7):\n",
    "                end = (i + 1)*121\n",
    "                m = np.mean(X_train[:,start:end]) #mean of training\n",
    "                s = np.std(X_train[:,start:end]) #mean of testing\n",
    "                X_train[:,start:end] = norm(X_train[:,start:end], m, s)\n",
    "                X_test[:,start:end] = norm(X_test[:,start:end], m, s)\n",
    "                start = end\n",
    "\n",
    "\n",
    "            model = keras.Sequential()\n",
    "            model.add(layers.Dense(764, activation='relu', input_shape=[847]))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dense(364, activation='relu'))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dense(264, activation='relu'))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dense(164, activation='relu'))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dense(64, activation='relu'))\n",
    "            model.add(layers.Dense(1, activation = 'linear'))\n",
    "\n",
    "            optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "            model.compile(loss='mse',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['mae', 'mse'])\n",
    "\n",
    "            history = model.fit(X_train, y_train, epochs = epochs, batch_size = batchsize, \n",
    "                                validation_data = (X_test, y_test))\n",
    "\n",
    "            loss_train = np.sqrt(history.history['loss'])\n",
    "            loss_test = np.sqrt(history.history['val_loss'])\n",
    "\n",
    "            #Determining Best Model\n",
    "            lowest_test_loss = np.min(loss_test)\n",
    "\n",
    "            if fold == 0:\n",
    "                model_best = model\n",
    "                lowest_validation = lowest_test_loss\n",
    "            elif fold > 0:\n",
    "                if lowest_test_loss < lowest_validation:\n",
    "                    model_best = model\n",
    "                    lowest_validation = lowest_test_loss\n",
    "\n",
    "            training_loss_fold[fold] = loss_train\n",
    "            testing_loss_fold[fold] = loss_test\n",
    "\n",
    "        return model_best, training_loss_fold, testing_loss_fold, lowest_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0\n",
      "Fold 1\n",
      "Epoch 1/200\n",
      "136/136 [==============================] - 3s 12ms/step - loss: 3996.8661 - mae: 47.5696 - mse: 3996.8661 - val_loss: 4418.9736 - val_mae: 53.6399 - val_mse: 4418.9736\n",
      "Epoch 2/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 1173.2443 - mae: 23.0359 - mse: 1173.2443 - val_loss: 1623.4899 - val_mae: 29.1167 - val_mse: 1623.4899\n",
      "Epoch 3/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 1033.0300 - mae: 21.5304 - mse: 1033.0300 - val_loss: 1073.8306 - val_mae: 22.7746 - val_mse: 1073.8306\n",
      "Epoch 4/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 955.8752 - mae: 21.0219 - mse: 955.8752 - val_loss: 1088.7395 - val_mae: 22.8790 - val_mse: 1088.7395\n",
      "Epoch 5/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 863.6479 - mae: 20.0561 - mse: 863.6479 - val_loss: 1419.6246 - val_mae: 25.4977 - val_mse: 1419.6246\n",
      "Epoch 6/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 874.0026 - mae: 20.1933 - mse: 874.0026 - val_loss: 1092.2720 - val_mae: 21.8159 - val_mse: 1092.2720\n",
      "Epoch 7/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 805.8162 - mae: 19.4490 - mse: 805.8162 - val_loss: 1076.1113 - val_mae: 21.1567 - val_mse: 1076.1113\n",
      "Epoch 8/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 730.3164 - mae: 18.5826 - mse: 730.3164 - val_loss: 1120.4689 - val_mae: 21.2821 - val_mse: 1120.4689\n",
      "Epoch 9/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 722.5928 - mae: 18.5206 - mse: 722.5928 - val_loss: 1180.0759 - val_mae: 22.1912 - val_mse: 1180.0759\n",
      "Epoch 10/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 706.1429 - mae: 18.4967 - mse: 706.1429 - val_loss: 1067.0295 - val_mae: 20.7189 - val_mse: 1067.0295\n",
      "Epoch 11/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 682.0611 - mae: 18.1469 - mse: 682.0611 - val_loss: 1173.2314 - val_mae: 21.4622 - val_mse: 1173.2314\n",
      "Epoch 12/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 635.0781 - mae: 17.3344 - mse: 635.0781 - val_loss: 1267.7173 - val_mae: 21.8605 - val_mse: 1267.7173\n",
      "Epoch 13/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 601.3455 - mae: 17.0740 - mse: 601.3455 - val_loss: 1347.3395 - val_mae: 22.4672 - val_mse: 1347.3395\n",
      "Epoch 14/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 643.3174 - mae: 17.5287 - mse: 643.3174 - val_loss: 1294.4769 - val_mae: 21.2669 - val_mse: 1294.4769\n",
      "Epoch 15/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 556.2824 - mae: 16.5479 - mse: 556.2824 - val_loss: 1101.8318 - val_mae: 20.8381 - val_mse: 1101.8318\n",
      "Epoch 16/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 554.1482 - mae: 16.4734 - mse: 554.1482 - val_loss: 1193.1641 - val_mae: 21.4142 - val_mse: 1193.1641\n",
      "Epoch 17/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 533.3921 - mae: 16.2915 - mse: 533.3921 - val_loss: 1280.7740 - val_mae: 21.6924 - val_mse: 1280.7740\n",
      "Epoch 18/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 498.5855 - mae: 15.6686 - mse: 498.5855 - val_loss: 1213.0367 - val_mae: 20.8230 - val_mse: 1213.0367\n",
      "Epoch 19/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 509.3656 - mae: 15.7068 - mse: 509.3656 - val_loss: 1206.4940 - val_mae: 20.9289 - val_mse: 1206.4940\n",
      "Epoch 20/200\n",
      "136/136 [==============================] - 2s 12ms/step - loss: 477.3319 - mae: 15.5164 - mse: 477.3319 - val_loss: 1092.6917 - val_mae: 20.3438 - val_mse: 1092.6917\n",
      "Epoch 21/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 456.2418 - mae: 15.2194 - mse: 456.2418 - val_loss: 1126.3783 - val_mae: 20.7337 - val_mse: 1126.3783\n",
      "Epoch 22/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 457.6222 - mae: 15.0307 - mse: 457.6222 - val_loss: 1101.2251 - val_mae: 20.1441 - val_mse: 1101.2251\n",
      "Epoch 23/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 448.1040 - mae: 14.9495 - mse: 448.1040 - val_loss: 1105.4429 - val_mae: 20.2132 - val_mse: 1105.4429\n",
      "Epoch 24/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 424.3601 - mae: 14.7490 - mse: 424.3601 - val_loss: 1098.7358 - val_mae: 20.6175 - val_mse: 1098.7358\n",
      "Epoch 25/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 425.4198 - mae: 14.5325 - mse: 425.4198 - val_loss: 1118.9166 - val_mae: 20.2713 - val_mse: 1118.9166\n",
      "Epoch 26/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 433.6859 - mae: 14.6061 - mse: 433.6859 - val_loss: 1078.2521 - val_mae: 20.1245 - val_mse: 1078.2521\n",
      "Epoch 27/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 395.9919 - mae: 14.1292 - mse: 395.9919 - val_loss: 1117.6141 - val_mae: 19.8405 - val_mse: 1117.6141\n",
      "Epoch 28/200\n",
      "136/136 [==============================] - 2s 12ms/step - loss: 386.6085 - mae: 13.9382 - mse: 386.6085 - val_loss: 1067.3033 - val_mae: 20.0663 - val_mse: 1067.3033\n",
      "Epoch 29/200\n",
      "136/136 [==============================] - 2s 12ms/step - loss: 400.4817 - mae: 14.0092 - mse: 400.4817 - val_loss: 1155.6510 - val_mae: 21.4690 - val_mse: 1155.6510\n",
      "Epoch 30/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 369.2762 - mae: 13.6503 - mse: 369.2762 - val_loss: 1063.7367 - val_mae: 19.8751 - val_mse: 1063.7367\n",
      "Epoch 31/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 327.5378 - mae: 12.9603 - mse: 327.5378 - val_loss: 1077.9497 - val_mae: 20.3242 - val_mse: 1077.9497\n",
      "Epoch 32/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 339.0982 - mae: 13.1509 - mse: 339.0982 - val_loss: 1062.5377 - val_mae: 19.4141 - val_mse: 1062.5377\n",
      "Epoch 33/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 319.3044 - mae: 12.7925 - mse: 319.3044 - val_loss: 1106.6432 - val_mae: 19.7914 - val_mse: 1106.6432\n",
      "Epoch 34/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 337.0212 - mae: 13.1229 - mse: 337.0212 - val_loss: 1081.8577 - val_mae: 19.9698 - val_mse: 1081.8577\n",
      "Epoch 35/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 340.8244 - mae: 13.1652 - mse: 340.8244 - val_loss: 1080.1608 - val_mae: 20.1501 - val_mse: 1080.1608\n",
      "Epoch 36/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 336.8126 - mae: 13.1682 - mse: 336.8126 - val_loss: 1062.1978 - val_mae: 19.5108 - val_mse: 1062.1978\n",
      "Epoch 37/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 319.5845 - mae: 12.6900 - mse: 319.5845 - val_loss: 1097.1826 - val_mae: 20.4914 - val_mse: 1097.1826\n",
      "Epoch 38/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 303.5118 - mae: 12.2829 - mse: 303.5118 - val_loss: 1052.9136 - val_mae: 19.6928 - val_mse: 1052.9136\n",
      "Epoch 39/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 305.6823 - mae: 12.5654 - mse: 305.6823 - val_loss: 1048.1683 - val_mae: 20.1827 - val_mse: 1048.1683\n",
      "Epoch 40/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 281.8296 - mae: 12.0467 - mse: 281.8296 - val_loss: 1051.1758 - val_mae: 19.0441 - val_mse: 1051.1758\n",
      "Epoch 41/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 258.7074 - mae: 11.6226 - mse: 258.7074 - val_loss: 1076.8176 - val_mae: 19.7349 - val_mse: 1076.8176\n",
      "Epoch 42/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 318.9158 - mae: 12.5051 - mse: 318.9158 - val_loss: 1034.7974 - val_mae: 20.0689 - val_mse: 1034.7974\n",
      "Epoch 43/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 280.6515 - mae: 12.1359 - mse: 280.6515 - val_loss: 1053.8641 - val_mae: 19.4683 - val_mse: 1053.8641\n",
      "Epoch 44/200\n",
      " 71/136 [==============>...............] - ETA: 0s - loss: 298.1236 - mae: 12.0908 - mse: 298.1236"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ae6388063acd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_simulations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel_sim_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowest_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFFNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Testing model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-d25cfaf1c6ab>\u001b[0m in \u001b[0;36mFFNN\u001b[1;34m(X, y, epochs, folds, batchsize, sim)\u001b[0m\n\u001b[0;32m     54\u001b[0m                         metrics=['mae', 'mse'])\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             history = model.fit(X_train, y_train, epochs = epochs, batch_size = batchsize, \n\u001b[0m\u001b[0;32m     57\u001b[0m                                 validation_data = (X_test, y_test))\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "n_simulations = 5\n",
    "epochs = 200\n",
    "batchsize = 64\n",
    "sim_train = np.zeros((n_simulations, epochs))\n",
    "sim_test = np.zeros((n_simulations, epochs))\n",
    "simulation_list = []\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for sim in range(n_simulations):\n",
    "        model_sim_best, Ltrain, Ltest, lowest_val = FFNN(vector_train, labels_train, epochs, k, batchsize, sim)\n",
    "\n",
    "        # Testing model\n",
    "        m_label = np.mean(vector_test)\n",
    "        s_label = np.std(vector_test)\n",
    "        X_model = norm(vector_test, m_label, s_label)\n",
    "        R = model_sim_best.evaluate(X_model, labels_test, verbose = 0)\n",
    "        simulation_list.append(R[0])\n",
    "\n",
    "        if sim == 0:\n",
    "            model_best = model_sim_best\n",
    "            val_marker = lowest_val\n",
    "        else:\n",
    "            if lowest_val < val_marker:\n",
    "                model_best = model_sim_best\n",
    "                val_marker = lowest_val\n",
    "\n",
    "        sim_train[sim] = np.mean(Ltrain, axis = 0)\n",
    "        sim_test[sim] = np.mean(Ltest, axis = 0)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.plot(range(epochs), sim_train[sim], '--', label = 'Simulation {}'.format(sim+1))\n",
    "        plt.figure(2)\n",
    "        plt.plot(range(epochs), sim_test[sim], label = 'Simulation {}'.format(sim+1))\n",
    "\n",
    "\n",
    "    plt.figure(3)    \n",
    "    plt.plot(range(epochs), np.mean(sim_train, axis = 0), 'k--')\n",
    "    plt.figure(4)    \n",
    "    plt.plot(range(epochs), np.mean(sim_test, axis = 0), 'k')\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    titles = ['FFNN Simulation Training', 'FFNN Simulation Validation','FFNN Average Training', 'FFNN Average Validation']\n",
    "    for i in range(4):\n",
    "        plt.figure(i+1)\n",
    "        plt.title(titles[i])\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Root Mean Square Error')\n",
    "        if i == 0 or i == 1:     \n",
    "            plt.legend()   \n",
    "\n",
    "    overfit = np.sqrt(simulation_list) - np.min(sim_train, axis = 1)        \n",
    "    train_min_mean = np.mean(np.min(sim_train, axis = 1))\n",
    "    train_min_std = np.std(np.min(sim_train, axis = 1))\n",
    "    test_min_mean = np.mean(np.min(sim_test, axis = 1))\n",
    "    test_min_std = np.std(np.min(sim_test, axis = 1))\n",
    "    print('Final Training Mean RMSE:',train_min_mean)\n",
    "    print('Final Training STD RMSE:',train_min_std)\n",
    "    print('Final Validation Mean RMSE:',test_min_mean)\n",
    "    print('Final Validation STD RMSE:',test_min_std)\n",
    "    print('The Final Mean RMSE', np.mean(np.sqrt(simulation_list)))\n",
    "    print('The Final STD RMSE', np.std(np.sqrt(simulation_list)))\n",
    "    print('Overfit Mean', np.mean(overfit))\n",
    "    print('Overfit STD', np.std(overfit))\n",
    "    #-----------------Saving model------------------\n",
    "    # serialize model to JSON\n",
    "    model_json = model_best.to_json()\n",
    "    with open(\"FFNN_model_best.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model_best.save_weights(\"FFNN_model_best.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial test RMSE = 91.97\n",
      "The final test RMSE on the model is 220.29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1d5b244c648>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prune(model):\n",
    "    epochs_prune = 1\n",
    "    batch = 1000\n",
    "    end_step = np.ceil(1.0 * len(vector_train)/batch).astype(np.int32) * epochs_prune\n",
    "    new_pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity = 0.25,\n",
    "                                                       final_sparsity = 0.25,\n",
    "                                                       begin_step = 0,\n",
    "                                                       end_step = end_step,\n",
    "                                                       frequency = 100)}\n",
    "\n",
    "    new_pruned_model = sparsity.prune_low_magnitude(model, **new_pruning_params)\n",
    "    new_pruned_model.compile(loss = tf.keras.losses.mean_squared_error, optimizer = 'adam', metrics=['mse'])\n",
    "    callbacks = [sparsity.UpdatePruningStep()]\n",
    "    new_pruned_model.fit(vector_train, labels_train,\n",
    "              batch_size = batch,\n",
    "              epochs = epochs_prune,\n",
    "              verbose = 1,\n",
    "              callbacks = callbacks)\n",
    "    #           validation_data = (x_val, y_val))\n",
    "\n",
    "    clear_output()\n",
    "    final_model = sparsity.strip_pruning(new_pruned_model)\n",
    "    score = new_pruned_model.evaluate(vector_test, labels_test, verbose = 0)\n",
    "    print('initial test RMSE = {:.2f}'.format(np.mean(np.sqrt(simulation_list))))\n",
    "    print('The final test RMSE on the model is {:.2f}'.format(np.sqrt(score[0])))\n",
    "    \n",
    "    return new_pruned_model\n",
    "\n",
    "prune(model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    print('Working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Input shape: (50, 50) using Device: cpu took: 0.05\n",
      "Input shape: (100, 100) using Device: cpu took: 0.04\n",
      "Input shape: (500, 500) using Device: cpu took: 0.04\n",
      "Input shape: (10000, 10000) using Device: cpu took: 4.55\n",
      "----------------------------------------\n",
      "Input shape: (50, 50) using Device: gpu took: 0.05\n",
      "Input shape: (100, 100) using Device: gpu took: 0.04\n",
      "Input shape: (500, 500) using Device: gpu took: 0.04\n",
      "Input shape: (10000, 10000) using Device: gpu took: 0.92\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "# Choose which device you want to test on: either 'cpu' or 'gpu'\n",
    "devices = ['cpu', 'gpu']\n",
    "\n",
    "# Choose size of the matrix to be used.\n",
    "# Make it bigger to see bigger benefits of parallel computation\n",
    "shapes = [(50, 50), (100, 100), (500, 500), (10000, 10000)]\n",
    "\n",
    "\n",
    "def compute_operations(device, shape):\n",
    "    \"\"\"Run a simple set of operations on a matrix of given shape on given device\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : the type of device to use, either 'cpu' or 'gpu' \n",
    "    shape : a tuple for the shape of a 2d tensor, e.g. (10, 10)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : results of the operations as the time taken\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define operations to be computed on selected device\n",
    "    with tf.device(device):\n",
    "        random_matrix = tf.random.uniform(shape=shape, minval=0, maxval=1)\n",
    "        dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "        sum_operation = tf.reduce_sum(dot_operation)\n",
    "#     print(sum_operation)\n",
    "    # Time the actual runtime of the operations\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    start_time = datetime.now()\n",
    "#     with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True)) as session:\n",
    "#             result = session.run(dot_operation)\n",
    "    sess = tf.compat.v1.Session()\n",
    "    result = sess.run(sum_operation)\n",
    "    elapsed_time = datetime.now() - start_time\n",
    "\n",
    "    return result, elapsed_time\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Run the computations and print summary of each run\n",
    "    for device in devices:\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        for shape in shapes:\n",
    "            _, time_taken = compute_operations(device, shape)\n",
    "\n",
    "            # Print the result and also the time taken on the selected device\n",
    "            print(\"Input shape:\", shape, \"using Device:\", device, \"took: {:.2f}\".format(time_taken.seconds + time_taken.microseconds/1e6))\n",
    "            #print(\"Computation on shape:\", shape, \"using Device:\", device, \"took:\")\n",
    "\n",
    "    print(\"--\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
